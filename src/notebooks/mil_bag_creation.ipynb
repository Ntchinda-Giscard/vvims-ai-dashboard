{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/teamspace/studios/this_studio/src/notebooks'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/teamspace/studios/this_studio'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Set paths - replace these with your actual dataset paths\n",
    "BASE_PATH = \"raw\"\n",
    "TRAIN_SPLIT_PATH = os.path.join(BASE_PATH, \"Action_Regnition_splits/train_001.txt\")\n",
    "TEST_SPLIT_PATH = os.path.join(BASE_PATH, \"Action_Regnition_splits/test_001.txt\")\n",
    "FEATURES_PATH = os.path.join(BASE_PATH, \"features\")  # Path where your pre-extracted features are stored\n",
    "OUTPUT_PATH = os.path.join(BASE_PATH, \"mil_bags\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class map: ===> {'Normal': 0, 'Abuse': 1, 'Arrest': 2, 'Arson': 3, 'Assault': 4}\n",
      "('Abuse013_x264.mp4', 1)\n"
     ]
    }
   ],
   "source": [
    "def parse_split_file(split_file_path):\n",
    "    # \"Burglary\", \"Explosion\", \"Fighting\", \"RoadAccidents\", \"Robbery\", \"Shooting\", \"Shoplifting\", \"Stealing\", \"Vandalism\"\n",
    "    videos = []\n",
    "    labels = []\n",
    "    class_names = [\"Normal\", \"Abuse\", \"Arrest\", \"Arson\", \"Assault\"]\n",
    "    class_map = {name: idx for idx, name in enumerate(class_names)}\n",
    "    print(f\"Class map: ===> {class_map}\")\n",
    "    \n",
    "    with open(split_file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split(\"/\")\n",
    "            # print(f\"Print parts: ===> {parts}\")\n",
    "\n",
    "            if len(parts) >= 2:\n",
    "\n",
    "                video_path = parts[1]\n",
    "                category = parts[0]\n",
    "                if category in class_map:\n",
    "                    label = class_map[category]\n",
    "                    videos.append(video_path)\n",
    "                    labels.append(label)\n",
    "    \n",
    "    return videos, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Organize features into MIL bags\n",
    "def organize_into_bags():\n",
    "    # Parse split files\n",
    "    train_videos, train_labels = parse_split_file(TRAIN_SPLIT_PATH)\n",
    "    test_videos, test_labels = parse_split_file(TEST_SPLIT_PATH)\n",
    "    \n",
    "    print(f\"Found {len(train_videos)} training videos and {len(test_videos)} testing videos\")\n",
    "    \n",
    "    # Create training bags\n",
    "    train_bags = []\n",
    "    train_bag_labels = []\n",
    "    \n",
    "    for i, (video_name, label) in enumerate(zip(train_videos, train_labels)):\n",
    "        # Get video ID/name from the path\n",
    "        video_id = os.path.splitext(os.path.basename(video_name))[0]\n",
    "        \n",
    "        # Load pre-extracted features for this video\n",
    "        feature_path = os.path.join(FEATURES_PATH, f\"{video_id}.npy\")\n",
    "        \n",
    "        if os.path.exists(feature_path):\n",
    "            features = np.load(feature_path)\n",
    "            train_bags.append(features)\n",
    "            train_bag_labels.append(label)\n",
    "            print(f\"Added training bag {i+1}/{len(train_videos)}: {video_id}, shape: {features.shape}\")\n",
    "        else:\n",
    "            print(f\"Warning: Features not found for {video_id}\")\n",
    "    \n",
    "    # Create testing bags\n",
    "    test_bags = []\n",
    "    test_bag_labels = []\n",
    "    \n",
    "    for i, (video_name, label) in enumerate(zip(test_videos, test_labels)):\n",
    "        # Get video ID/name from the path\n",
    "        video_id = os.path.splitext(os.path.basename(video_name))[0]\n",
    "        \n",
    "        # Load pre-extracted features for this video\n",
    "        feature_path = os.path.join(FEATURES_PATH, f\"{video_id}.npy\")\n",
    "        \n",
    "        if os.path.exists(feature_path):\n",
    "            features = np.load(feature_path)\n",
    "            test_bags.append(features)\n",
    "            test_bag_labels.append(label)\n",
    "            print(f\"Added testing bag {i+1}/{len(test_videos)}: {video_id}, shape: {features.shape}\")\n",
    "        else:\n",
    "            print(f\"Warning: Features not found for {video_id}\")\n",
    "    \n",
    "    # Save the organized bags\n",
    "    print(\"Saving organized MIL bags...\")\n",
    "    \n",
    "    with open(os.path.join(OUTPUT_PATH, 'train_bags.pkl'), 'wb') as f:\n",
    "        pickle.dump((train_bags, train_bag_labels), f)\n",
    "    \n",
    "    with open(os.path.join(OUTPUT_PATH, 'test_bags.pkl'), 'wb') as f:\n",
    "        pickle.dump((test_bags, test_bag_labels), f)\n",
    "    \n",
    "    print(f\"Data organization complete!\")\n",
    "    print(f\"Created {len(train_bags)} training bags and {len(test_bags)} testing bags\")\n",
    "    print(f\"Saved to {OUTPUT_PATH}\")\n",
    "    \n",
    "    # Print class distribution\n",
    "    classes = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]\n",
    "    class_names = [\"Normal\", \"Abuse\", \"Arrest\", \"Arson\", \"Assault\", \"Burglary\", \n",
    "                  \"Explosion\", \"Fighting\", \"RoadAccidents\", \"Robbery\", \n",
    "                  \"Shooting\", \"Shoplifting\", \"Stealing\", \"Vandalism\"]\n",
    "    \n",
    "    print(\"\\nTraining class distribution:\")\n",
    "    for c, name in zip(classes, class_names):\n",
    "        count = train_bag_labels.count(c)\n",
    "        print(f\"{name}: {count} videos\")\n",
    "    \n",
    "    print(\"\\nTesting class distribution:\")\n",
    "    for c, name in zip(classes, class_names):\n",
    "        count = test_bag_labels.count(c)\n",
    "        print(f\"{name}: {count} videos\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    organize_into_bags()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
